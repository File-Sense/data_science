{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install nltk\n",
        "%pip install pycocoevalcap"
      ],
      "metadata": {
        "id": "s4MObugq47Qh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63de8d89-6a00-48c2-f0fd-d3b277c86f5f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n",
            "Collecting pycocoevalcap\n",
            "  Downloading pycocoevalcap-1.2-py3-none-any.whl (104.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.3/104.3 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from pycocoevalcap) (2.0.7)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools>=2.0.2->pycocoevalcap) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pycocotools>=2.0.2->pycocoevalcap) (1.25.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap) (1.16.0)\n",
            "Installing collected packages: pycocoevalcap\n",
            "Successfully installed pycocoevalcap-1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YWp5oSQw4mZ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf3c7fd3-9099-4d00-cc15-738a6a2a37f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import os\n",
        "import nltk\n",
        "import json\n",
        "import torch\n",
        "import urllib\n",
        "import pickle\n",
        "import zipfile\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from collections import Counter\n",
        "from pycocotools.coco import COCO\n",
        "from model import Encoder, Decoder\n",
        "from torchvision import transforms\n",
        "from collections import defaultdict\n",
        "from pycocoevalcap.eval import COCOEvalCap\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('opt' , exist_ok=True)\n",
        "os.chdir( '/content/opt' )\n",
        "!git clone 'https://github.com/cocodataset/cocoapi.git'"
      ],
      "metadata": {
        "id": "jGgcGqTk6kCa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0df570b-e46c-454a-efd1-5f4c564a0764"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cocoapi'...\n",
            "remote: Enumerating objects: 975, done.\u001b[K\n",
            "remote: Total 975 (delta 0), reused 0 (delta 0), pack-reused 975\u001b[K\n",
            "Receiving objects: 100% (975/975), 11.72 MiB | 16.98 MiB/s, done.\n",
            "Resolving deltas: 100% (576/576), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/opt/cocoapi')\n",
        "annotations_trainval2014 = 'http://images.cocodataset.org/annotations/annotations_trainval2014.zip'\n",
        "urllib.request.urlretrieve(annotations_trainval2014 , filename = 'annotations_trainval2014.zip' )"
      ],
      "metadata": {
        "id": "IDLYVsQ16n1P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64c057bd-d952-4ae0-a977-f42409dfee8f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('annotations_trainval2014.zip', <http.client.HTTPMessage at 0x7b82a7394f40>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with zipfile.ZipFile('annotations_trainval2014.zip' , 'r') as zip_ref:\n",
        "  zip_ref.extractall( '/content/opt/cocoapi'  )\n",
        "\n",
        "try:\n",
        "  os.remove( 'annotations_trainval2014.zip' )\n",
        "  print('zip removed')\n",
        "except:\n",
        "  None"
      ],
      "metadata": {
        "id": "3p-e2kc-6qUa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "640fde72-48a0-42ec-d0d7-e83438917446"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "zip removed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/opt/cocoapi')\n",
        "\n",
        "val2014 = 'http://images.cocodataset.org/zips/val2014.zip'\n",
        "\n",
        "urllib.request.urlretrieve(val2014, 'val2014')"
      ],
      "metadata": {
        "id": "U2uVABlR7-bw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a82be1c-dced-44a6-d92e-6ddc410fa4f8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('val2014', <http.client.HTTPMessage at 0x7b82a7395000>)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/opt/cocoapi')\n",
        "with zipfile.ZipFile( 'val2014' , 'r' ) as zip_ref:\n",
        "  zip_ref.extractall( 'images' )\n",
        "\n",
        "try:\n",
        "  os.remove( 'val2014' )\n",
        "  print('zip removed')\n",
        "except:\n",
        "  None"
      ],
      "metadata": {
        "id": "PzmZNCNb8Uzt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da5cdb36-db91-4304-fd92-5bb7a094935b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "zip removed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Vocabulary(object):\n",
        "\n",
        "    def __init__(self,\n",
        "        vocab_threshold,\n",
        "        vocab_file='./vocab.pkl',\n",
        "        start_word=\"<start>\",\n",
        "        end_word=\"<end>\",\n",
        "        unk_word=\"<unk>\",\n",
        "        annotations_file='../cocoapi/annotations/captions_train2014.json',\n",
        "        vocab_from_file=False):\n",
        "        \"\"\"Initialize the vocabulary.\n",
        "        Args:\n",
        "          vocab_threshold: Minimum word count threshold.\n",
        "          vocab_file: File containing the vocabulary.\n",
        "          start_word: Special word denoting sentence start.\n",
        "          end_word: Special word denoting sentence end.\n",
        "          unk_word: Special word denoting unknown words.\n",
        "          annotations_file: Path for train annotation file.\n",
        "          vocab_from_file: If False, create vocab from scratch & override any existing vocab_file\n",
        "                           If True, load vocab from from existing vocab_file, if it exists\n",
        "        \"\"\"\n",
        "        self.vocab_threshold = vocab_threshold\n",
        "        self.vocab_file = vocab_file\n",
        "        self.start_word = start_word\n",
        "        self.end_word = end_word\n",
        "        self.unk_word = unk_word\n",
        "        self.annotations_file = annotations_file\n",
        "        self.vocab_from_file = vocab_from_file\n",
        "        self.get_vocab()\n",
        "\n",
        "    def get_vocab(self):\n",
        "        \"\"\"Load the vocabulary from file OR build the vocabulary from scratch.\"\"\"\n",
        "        if os.path.exists(self.vocab_file) & self.vocab_from_file:\n",
        "            with open(self.vocab_file, 'rb') as f:\n",
        "                vocab = pickle.load(f)\n",
        "                self.word2idx = vocab.word2idx\n",
        "                self.idx2word = vocab.idx2word\n",
        "            print('Vocabulary successfully loaded from vocab.pkl file!')\n",
        "        else:\n",
        "            self.build_vocab()\n",
        "            with open(self.vocab_file, 'wb') as f:\n",
        "                pickle.dump(self, f)\n",
        "\n",
        "    def build_vocab(self):\n",
        "        \"\"\"Populate the dictionaries for converting tokens to integers (and vice-versa).\"\"\"\n",
        "        self.init_vocab()\n",
        "        self.add_word(self.start_word)\n",
        "        self.add_word(self.end_word)\n",
        "        self.add_word(self.unk_word)\n",
        "        self.add_captions()\n",
        "\n",
        "    def init_vocab(self):\n",
        "        \"\"\"Initialize the dictionaries for converting tokens to integers (and vice-versa).\"\"\"\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.idx = 0\n",
        "\n",
        "    def add_word(self, word):\n",
        "        \"\"\"Add a token to the vocabulary.\"\"\"\n",
        "        if not word in self.word2idx:\n",
        "            self.word2idx[word] = self.idx\n",
        "            self.idx2word[self.idx] = word\n",
        "            self.idx += 1\n",
        "\n",
        "    def add_captions(self):\n",
        "        \"\"\"Loop over training captions and add all tokens to the vocabulary that meet or exceed the threshold.\"\"\"\n",
        "        coco = COCO(self.annotations_file)\n",
        "        counter = Counter()\n",
        "        ids = coco.anns.keys()\n",
        "        for i, id in enumerate(ids):\n",
        "            caption = str(coco.anns[id]['caption'])\n",
        "            tokens = nltk.tokenize.word_tokenize(caption.lower())\n",
        "            counter.update(tokens)\n",
        "\n",
        "            if i % 100000 == 0:\n",
        "                print(\"[%d/%d] Tokenizing captions...\" % (i, len(ids)))\n",
        "\n",
        "        words = [word for word, cnt in counter.items() if cnt >= self.vocab_threshold]\n",
        "\n",
        "        for i, word in enumerate(words):\n",
        "            self.add_word(word)\n",
        "\n",
        "    def __call__(self, word):\n",
        "        if not word in self.word2idx:\n",
        "            return self.word2idx[self.unk_word]\n",
        "        return self.word2idx[word]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.word2idx)"
      ],
      "metadata": {
        "id": "ne5GlkCj5EP8"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/vocab.pkl', 'rb') as f:\n",
        "    vocab = pickle.load(f)"
      ],
      "metadata": {
        "id": "zJedQk6L5Bzt"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "encoder_file = 'encoder-3.pkl'\n",
        "decoder_file = 'decoder-3.pkl'\n",
        "embed_size = 256\n",
        "hidden_size = 512\n",
        "vocab_size = len(vocab)\n",
        "encoder = Encoder(embed_size).eval().to(device)\n",
        "decoder = Decoder(embed_size, hidden_size, vocab_size).eval().to(device)\n",
        "encoder.load_state_dict(torch.load(os.path.join('/content/models', encoder_file), map_location=device))\n",
        "decoder.load_state_dict(torch.load(os.path.join('/content/models', decoder_file), map_location=device))"
      ],
      "metadata": {
        "id": "_gx0p8MW5bnL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd83fd9d-8234-4688-f121-02041b00a40c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:01<00:00, 81.9MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Image transformation\n",
        "transform_image = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])"
      ],
      "metadata": {
        "id": "qij8_muY5dEr"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_sentence(output):\n",
        "    cleaned_list = []\n",
        "    for index in output:\n",
        "        if  (index == 1) :\n",
        "            continue\n",
        "        cleaned_list.append(vocab.idx2word[index])\n",
        "    cleaned_list = cleaned_list[1:-1] # Discard <start> and <end>\n",
        "\n",
        "    sentence = ' '.join(cleaned_list) # Convert list of string to\n",
        "    sentence = sentence.capitalize()\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "8ye_sAUK_cf9"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_captions(encoder, decoder, image_path, vocab):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform_image(image).unsqueeze(0).to(device)\n",
        "\n",
        "    features = encoder(image).unsqueeze(1)\n",
        "    output = decoder.sample(features)\n",
        "    sentence = clean_sentence(output)\n",
        "\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "IS_770L95e5Y"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_all_captions(encoder, decoder, image_dir, dataset, vocab):\n",
        "    results = []\n",
        "    for img_id in dataset.imgs:\n",
        "        img_path = os.path.join(image_dir, dataset.imgs[img_id]['file_name'])\n",
        "        caption = generate_captions(encoder, decoder, img_path, vocab)\n",
        "        results.append({'image_id': img_id, 'caption': caption})\n",
        "    return results"
      ],
      "metadata": {
        "id": "VNFgqrys5s47"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the COCO validation annotations\n",
        "os.chdir('/content/opt/cocoapi/annotations')\n",
        "annFile = 'instances_val2014.json'\n",
        "coco = COCO(annFile)"
      ],
      "metadata": {
        "id": "caUFJmIw5vlP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8182e7de-42ab-4247-d137-4309895a63e8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=9.04s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming image_dir points to the folder containing validation images\n",
        "image_dir = '/content/opt/cocoapi/images/val2014'"
      ],
      "metadata": {
        "id": "-BnkEJGN6G8c"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate captions for the validation images\n",
        "generated_captions = generate_all_captions(encoder, decoder, image_dir, coco, vocab)"
      ],
      "metadata": {
        "id": "9Wep2ZcR6Kky"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del generated_captions"
      ],
      "metadata": {
        "id": "T6dSraUmcSN6"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the generated captions to a JSON file\n",
        "with open('/content/generated_captions.json', 'w') as f:\n",
        "    json.dump(generated_captions, f)"
      ],
      "metadata": {
        "id": "CroPkAJ06Oht"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the reference captions\n",
        "coco_caps = COCO('/content/opt/cocoapi/annotations/captions_val2014.json')"
      ],
      "metadata": {
        "id": "ZrlpURDZ6TEc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cb14bd6-dd50-4372-98d2-5ced719183f9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=1.00s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare for evaluation\n",
        "coco_res = coco_caps.loadRes('/content/generated_captions.json')"
      ],
      "metadata": {
        "id": "IBrS5rOr6VXH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac05852a-9f34-41a5-f8f6-d8c7e99853ab"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and preparing results...\n",
            "DONE (t=0.10s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a COCOEval object by passing the reference and generated captions\n",
        "cocoEval = COCOEvalCap(coco_caps, coco_res)"
      ],
      "metadata": {
        "id": "wsCwKttX6Wdu"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate for the specified image IDs\n",
        "cocoEval.params['image_id'] = coco_res.getImgIds()"
      ],
      "metadata": {
        "id": "txYW-iDe6Y30"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the results for all metrics\n",
        "cocoEval.evaluate()"
      ],
      "metadata": {
        "id": "8xABO7xv6Z8g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775
        },
        "outputId": "7ec1ebcb-cb3a-4e5c-aa92-56eac6e75387"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokenization...\n",
            "setting up scorers...\n",
            "Downloading stanford-corenlp-3.6.0 for SPICE ...\n",
            "Progress: 384.5M / 384.5M (100.0%)\n",
            "Extracting stanford-corenlp-3.6.0 ...\n",
            "Done.\n",
            "computing Bleu score...\n",
            "{'testlen': 406541, 'reflen': 399519, 'guess': [406541, 366037, 325533, 285029], 'correct': [245374, 104370, 38398, 14396]}\n",
            "ratio: 1.017576135302699\n",
            "Bleu_1: 0.604\n",
            "Bleu_2: 0.415\n",
            "Bleu_3: 0.273\n",
            "Bleu_4: 0.179\n",
            "computing METEOR score...\n",
            "METEOR: 0.188\n",
            "computing Rouge score...\n",
            "ROUGE_L: 0.445\n",
            "computing CIDEr score...\n",
            "CIDEr: 0.526\n",
            "computing SPICE score...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "Command '['java', '-jar', '-Xmx8G', 'spice-1.0.jar', '/usr/local/lib/python3.10/dist-packages/pycocoevalcap/spice/tmp/tmprwbvv0ki', '-cache', '/usr/local/lib/python3.10/dist-packages/pycocoevalcap/spice/cache', '-out', '/usr/local/lib/python3.10/dist-packages/pycocoevalcap/spice/tmp/tmpfmp51nmu', '-subset', '-silent']' died with <Signals.SIGKILL: 9>.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-620694ec9333>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Evaluate the results for all metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcocoEval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pycocoevalcap/eval.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscorers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'computing %s score...'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscorer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pycocoevalcap/spice/spice.py\u001b[0m in \u001b[0;36mcompute_score\u001b[0;34m(self, gts, res)\u001b[0m\n\u001b[1;32m     73\u001b[0m           \u001b[0;34m'-silent'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         ]\n\u001b[0;32m---> 75\u001b[0;31m         subprocess.check_call(spice_cmd, \n\u001b[0m\u001b[1;32m     76\u001b[0m             cwd=os.path.dirname(os.path.abspath(__file__)))\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36mcheck_call\u001b[0;34m(*popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcmd\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mcmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpopenargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command '['java', '-jar', '-Xmx8G', 'spice-1.0.jar', '/usr/local/lib/python3.10/dist-packages/pycocoevalcap/spice/tmp/tmprwbvv0ki', '-cache', '/usr/local/lib/python3.10/dist-packages/pycocoevalcap/spice/cache', '-out', '/usr/local/lib/python3.10/dist-packages/pycocoevalcap/spice/tmp/tmpfmp51nmu', '-subset', '-silent']' died with <Signals.SIGKILL: 9>."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the evaluation scores for each metric\n",
        "for metric, score in cocoEval.eval.items():\n",
        "    print(f'{metric}: {score:.3f}')"
      ],
      "metadata": {
        "id": "LWNkmEUl6a7B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5dbdf6e-fec9-448f-80bd-6c4794352f3e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bleu_1: 0.604\n",
            "Bleu_2: 0.415\n",
            "Bleu_3: 0.273\n",
            "Bleu_4: 0.179\n",
            "METEOR: 0.188\n",
            "ROUGE_L: 0.445\n",
            "CIDEr: 0.526\n"
          ]
        }
      ]
    }
  ]
}